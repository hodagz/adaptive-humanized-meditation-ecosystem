# musicgen_test.py
import torch
from transformers import MusicgenForConditionalGeneration, AutoProcessor
import scipy
from datetime import datetime
import os

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§ÙˆÙ„ÛŒÙ‡
model_id = "facebook/musicgen-small"
device = "cuda" if torch.cuda.is_available() else "cpu"

# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Ùˆ Ù¾Ø±Ø¯Ø§Ø²Ø´Ú¯Ø±
processor = AutoProcessor.from_pretrained(model_id)
model = MusicgenForConditionalGeneration.from_pretrained(model_id).to(device)

# Ù…ØªÙ† Ø±Ø§Ù‡Ù†Ù…Ø§ Ø¨Ø±Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ Ù…ÙˆØ³ÛŒÙ‚ÛŒ
prompt = "A relaxing, soothing ambient melody with soft pads and calm rhythm, instrumental only."

# Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ ÙˆØ±ÙˆØ¯ÛŒ
inputs = processor(text=[prompt], return_tensors="pt").to(device)

# ØªÙˆÙ„ÛŒØ¯ Ù…ÙˆØ³ÛŒÙ‚ÛŒ
audio_values = model.generate(**inputs, max_new_tokens=256)

# Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„ Ø®Ø±ÙˆØ¬ÛŒ Ø¨Ø§ ØªØ§Ø±ÛŒØ® Ùˆ Ø³Ø§Ø¹Øª
now = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
os.makedirs("outputs", exist_ok=True)
output_path = f"outputs/relaxing_music_{now}.wav"

# Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø®Ø±ÙˆØ¬ÛŒ
import os
import soundfile as sf

os.makedirs("outputs", exist_ok=True)  # ğŸ”§ Ù…Ø·Ù…Ø¦Ù† Ø´Ùˆ Ù¾ÙˆØ´Ù‡ Ù‡Ø³Øª

sf.write(output_path, audio_values[0].cpu().numpy(), samplerate=32000)

print(f"âœ… Music generated and saved at: {output_path}")
